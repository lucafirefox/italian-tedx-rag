 Buonasera, mi chiamo Giulio De Angeli, mi occupo di neuroscienze computazionali. Io da diversi anni lavoro all'Università di Cambridge in un posto incredibile che si chiama Bill Gates Building, donato e fondato dall'omonimo. Il mio compito consiste nell'applicare metodi di intelligenza artificiale, di AI, alla ricerca biomedica, in particolare all'identificazione di meccanismi della patologia. Ora, quando sono arrivato a Cambridge nel 2016, un professore mi disse che in un talk, se hai fortuna, puoi trasmettere al pubblico al massimo tre concetti, nel migliore dei casi. Beh, tanto vale che vi ridica subito. Io spero che stasera, quando tornerete a casa, di questo talk ricordiate queste tre cose. Primo, cos'è l'AI tradizionale, anche detta discriminativa. Secondo, cos'è l'AI di cui si parla tanto in questi giorni sui giornali, quella generativa, come c'è GPT. E terzo, come mai oggi chiederci se usare o no l'AI nella nostra vita, se introdurla nella nostra vita lavorativa o meno, è un falso problema, perché non è più una scelta. Partiamo. Primo, allora fino a qualche mese fa, con AI, con intelligenza artificiale, si intendeva per antonomasia una famiglia di tecniche, che sono le tecniche di deep learning, cioè le reti neurali. Ora, cosa fanno queste reti neurali? Sostanzialmente fanno due cose, classificazione e regressione. Allora, partiamo dalla prima. Classificazione vuol dire, voi prendete un dataset, per esempio un dataset di animali, di cui avete i dati di ciascuno, no? Ecco, e insegnate alla rete a classificarli, cioè dire questo è un cane, questo è un gatto, questo è un cavallo proprio come metteste le etichette su questi animali. Ve ne mostrate molti, a quel punto, alla fine del training, cioè dell'addestramento, avrete un programma informatico che è in grado di generalizzare. Vuol dire che gli date i dati di un nuovo animale e lui è in grado di dire, guarda, birba è un gatto. Ecco, questa era la classificazione. La regressione è la stessa cosa, solo che anziché mettere gli stampini, le classi, si stimano delle quantità numeriche. Per esempio, odiate gli stessi dati, insegnate gli animali quanto sono alti e alla fine avrete un programma che a grado di dire, ah, birba è alta 30 centimetri. Bravo! Ecco, questo era il cosa fa l'intelligenza artificiale, appunto, in particolare il deep learning. Vediamo il come. Beh, un indizio ve lo dà già il nome, appunto, reti neurali. Neurali non è una trovata di marketing, perché effettivamente, storicamente, furono introdotte proprio da dei lavori, ancora del 43, di un neurobiologo e un matematico, McCulloch e Pitts. E loro si proposero di simulare in un programma informatico come funziona un neurone. Come funziona un neurone? Cosa fa di mestiere? Il neurone è una cellula che prende in input segnali elettrici da diversi altri neuroni tramite desinarsi, dopodiché li fa convergere. Beh, prima li moltiplica per dei pesi, perché vedete i dendriti, che sono quei rami, ecco, in ingresso nel neurone, sono più grandi o più piccoli, quindi è come se li moltiplicaste, questi segnali, per dei pesi, e li fate convergere in un punto che, dopodiché, vengono sommati. Se la somma supera una certa soglia, viene sparato una specie di proiettile, che è un segnale elettrico, si chiama potenziale d'azione, che viene propagato a valle agli altri neuroni tramite, per l'appunto, delle altre sinapsi. Quindi, matematicamente, cosa fa questo neurone? Beh, è una cosa molto semplice. Prende dei segnali in ingresso, li moltiplica per dei coefficienti, e li somma, dopodiché applica una soglia, cioè un'operazione in cui fa maggiore di, praticamente, se è maggiore di, è vero, quindi viene mandato il segnale, altrimenti no. Ecco, quindi questo è, tra l'altro, piccola parentesi. Il fatto, vedete, che c'è un'operazione di soglia, è determinante, perché tutte le altre operazioni, somma e moltiplicazione, sono operazioni lineari. La soglia è un'operazione non lineare, non la potete rappresentare come una retta, no? È proprio il contrario, è uno scalino. E tutta la complessità della vita e del nostro cervello è figlia di questo, è figlia del fatto che ogni nostro neurone è una macchina non lineare, per l'appunto. E noi abbiamo tantissimi di questi neuroni, abbiamo appunto circa 10 alla 11, ecco, 100 miliardi. Bene, voi quindi se fate un programma informatico che prende degli input, li moltiplica per dei coefficienti, li somma e li passa attraverso una soglia, avete simulato un neurone. Se prendete tanti di questi neuroni artificiali, li mettete in una serie di layer, li mettete in fila, avete una rete neurale, per l'appunto. Bene, e a questo punto se questa rete neurale voi la addestrate con un certo trucco matematico, che non sto qui a raccontarvi perché è un po' complicato, potete insegnare a questa rete neurale a fare quello che vi ho detto prima, classificazione e regressione. E quindi avrete un programma informatico che data Birba, per esempio, vi dice Birba è un gatto. Ecco, ma cosa ci serve tutto questo in medicina della fattispecie? Beh, potrei fare un milione di esempi, ma tanto per dirne uno. Ho preso un esempio divertente dalla farmacologia, per cui vi chiedo, vi farò una domanda, vi chiedo nella vostra testa di rispondere, insomma. Secondo voi quanto costa commercializzare un nuovo farmaco? Costa mille dollari come un televisore? Costa 50 mila come un'auto di lusso? Costa un milione come un piccolo yacht? Costa 50 milioni come un aeroplano? O costa un miliardo come il pil di una piccola nazione? Beh, se avete detto un miliardo avete risposto correttamente. Anzi, alle volte è più di un miliardo. Per esempio, certi chemioterapici oncologici sono costati addirittura 4-5 billion, 4-5 miliardi. Sono spese enormi, appunto il pil di una piccola nazione. Per esempio, ecco, i chemioterapici 4-5, 4 miliardi addirittura. Ora, poniamo caso che avete ottenuto il finanziamento. Avete un miliardo, che è la spesa media per portare un farmaco in commercio, da spendere per portare il vostro farmaco in commercio. Il farmaco ha superato tutti i test preclinici sulle cellule e sui vari modelli preclinici, dopodiché è pronto per essere testato sull'uomo. Sull'uomo ci sono una serie di fasi e alla fine se ha funzionato viene approvato. Secondo voi qual è la probabilità, proprio statisticamente, che il farmaco alla fine venga approvato? Chi dice che è 10%, 30%, 50%, 70% o 90%? La risposta è che ottimisticamente è 10%. Nel migliore dei casi. Perché per esempio nel settore dove lavoro io, le malattie neurodegenerative, nel decennio fra 2003 e 2002, 2012, sono stati approvati lo 0,4% dei farmaci. Altro che 10. quasi sempre in questo caso per mancanza di efficacia clinica, cioè non è che era tossico, proprio non funzionava. Capite che avere un machine learning che ti aiuta prima di spendere un miliardo per qualcosa che non viene approvato, ti aiuta a capire se funzionerà o meno, è vagamente utile. Perché quel miliardo poteva essere utilizzato per finanziare altre ricerche. Quindi capire quali sono i farmaci dove è opportuno puntare, perché hanno la maggiore probabilità di funzionare, è leggermente utile. Motivo per cui non c'è una singola casa farmaceutica che ad oggi non stia investendo tantissimo nell'intelligenza artificiale. Chiaramente. Nel mio piccolo, quello che sto facendo io come ricercatore, è utilizzare queste tecniche per investigare i meccanismi della patologia. Cioè identificare i target, come la patologia fa i danni. Perché questo tipo di informazione è la chiave per trovare nuove terapie, chiaramente. Bene, quindi la prima cosa l'abbiamo fatta, no? Cioè, come funziona l'AI tradizionale? Ora chiediamoci invece l'AI, quella di cui si parla tanto sui giornali, che è quella generativa. Come fa un computer a inventare cose nuove? Dove risiede questa fantasia del computer? Beh, risiede in un presupposto matematico che è abbastanza semplice da raccontare. E nasce tutto da un'architettura che fu proposta già molti anni fa, che si chiama Autoencoder. L'Autoencoder è una rete neurale, identica a quella che abbiamo già vista come struttura. Cambia il task, cioè in cosa viene allenata. Perché ricordate, prima le allenavamo per fare classificazione e regressione, invece adesso questo Autoencoder è allenato su una cosa diversa, riprodurre l'input identico nell'output. Cioè tu gli mostri la foto di un gattino e vuoi che la stessa identica foto del gattino esca fuori dall'altro lato. Cioè la funzione identità, in pratica, voi direte, sì ma è un task stupido alla fine, cioè è proprio copiare l'input e copiarlo nell'output. Sì, ma c'è un constraint, una limitazione. E vedete, vedete com'è strutturata? Allora lei prende come in input, prende per esempio, se il task è foto di gattini, prende i pixel della foto del gattino, che sono migliaia, qui ne ho disegnati sette, per evidenti ragioni grafiche insomma. Però vedete che a un certo punto nella rete c'è un layer, un livello, che ha molti meno neuroni rispetto alla dimensione dell'input, in questo caso ne ha quattro per esempio. Se la rete è in grado di portare dall'input all'auto migliaia di foto, vuol dire che la seconda metà della rete è in grado di ricostruire la foto a partire da questi quattro numeri in croce. Per esempio 5,9, 2,6, eccetera, rappresentano quel gattino, quella foto di gattino. Qual è la magia? Che se voi prendete la seconda metà della rete, si chiama decoder, e iniziate a dare numeri a caso, vengono fuori foto di gattini nuove, che la rete non aveva mai visto perché non esistono, le ha inventate la macchina in quel momento, grazie al fatto che è stata trainata con migliaia di foto di gattini e quindi è appunto diventata in grado di fare questa funzione identità. Tutte le volte che una rete, un machine learning, un'intelligenza artificiale, è in grado di fare un task generativo, cioè appunto di inventare nuovi oggetti che prima non c'erano, si basa sempre su questo presupposto, una variazione sul tema di questo particolare meccanismo. Per esempio, nel 2017, un gruppo di ricercatori di Google Brain pubblicò un paper che si chiamava Attention is all you need, che era una variazione sul tema di questo meccanismo, un'architettura nuova si chiama Transformer. Il Transformer appunto, ecco, questo Transformer utilizza l'attenzione, è un meccanismo che serve sostanzialmente per filtrare le informazioni importanti, appunto da cui dare attenzione, dal rumore, da quelle poco importanti. E questo Transformer, a farla molto breve, era bravissimo sulle sequenze, per esempio il testo, che è appunto una sequenza. E un paio d'anni dopo, questo Transformer venne utilizzato, questa volta dai ricercatori di OpenAI, per fare GPT. Ecco, c'è GPT, prima si chiamava GPT, è stata trainata sul seguente task. Questo qua, cioè dato un testo, indovinami qual è la parola successiva. Cioè lui fa una distribuzione di probabilità, dice la più probabile è questa, e quindi prosegue questo testo. Ecco, la cosa incredibile è questa, che questo modello all'inizio funzionava bene, era stato trainato sull'intero World Wide Web, su tutto Internet, e funzionava discretamente bene. Al che hanno detto? Proviamo a aumentare la potenza computazionale, cioè mettiamo un computer più potente, e funzionava meglio. Al che? Ancora più potente, funzionava ancora meglio. E non sembrava finire mai, aveva una scalabilità, che era senza precedenti, e neanche i ricercatori stessi si immaginavano che avrebbe scalato così bene. Tant'è che oggi, per esempio, c'ha GBD che usate, lavora su 30.000 GPU. L'altro ieri, Zuckerberg, a Davos, ha annunciato che Meta acquisirà 350.000 GPU, mezza finanziaria italiana. Se una cosa che funziona bene con una GPU, la moltiplicate per 350.000, e questa continua a funzionare sempre meglio, vuol dire che avete vinto la lotteria, perché non funziona quasi mai così. Per dire, classificatori e regressori che vi ho mostrato prima, non è che se li fate 350.000 volte meglio, più grandi funzionano meglio, di solito smettono di funzionare a un certo punto. Invece qui continua a scalare, questa è la cosa incredibile. E più è grande la potenza di calcolo, più riesce a fare compiti avanzati, e proprio di ragionamento. Questo non se lo aspettava nessuno, gli stessi autori non se lo aspettavano. Quindi siamo al paradosso che noi sappiamo come costruirlo, c'ha GBD. L'avete visto voi. Non è altro che prendere questi transformer e allenarli su computer giganteschi. Però non sappiamo perché funziona, che è abbastanza incredibile. E vi ho detto, in realtà, allora, non sappiamo perché funziona, però qualcosina la possiamo intuire. Per esempio, c'è questa peculiarità. Vi ho detto, GBD è stato allenato sul task di indovinare qual è la parola più probabile che prosegue un determinato testo. E all'inizio faceva così, cioè faceva la distribuzione di probabilità, quella più probabile è questa, metteva quella. Il risultato era mediocre, cioè testi ripetitivi, poco interessanti, e insomma di qualità relativamente scarsa. Al che fu fatto il seguente cambiamento? Non prendermi la più probabile. Fai la distribuzione di probabilità, dopodiché mi scegli una delle più probabili, e la metti a caso. La scegli a caso. E curiosamente, venivano testi molto più interessanti, meno ripetitivi, più umani. Il che è molto interessante dal lato mio, neuroscientifico, perché, sapete, il nostro cervello non è una macchina deterministica, è probabilistica, per definizione, per molti motivi. Per esempio, i neuroni nel nostro cervello, le sinapsi dei neuroni, vi ho mostrato prima, sono i collegamenti fra un neurone e l'altro, sono grandi 20 nanometri, cioè 200 atomi, più o meno. Un sistema che è grande 200 atomi è descritto da una fisica, che è quella quantistica. La quantistica, nel momento in cui viene misurata, cioè, farla breve, determina degli effetti che sono macroscopici, in quel momento, è non deterministica, cioè probabilistica. Uno può stabilire la probabilità di un determinato evento, ma non può stabilire prima quale evento avverrà, tra le possibili combinazioni. Ecco, il nostro cervello lavora su quella scala, quindi, e lavora in un contesto quantistico. Non solo, tra l'altro, i neuroni del sistema nervoso centrale, diversamente dal periferico, hanno una probabilità di rilascio spontaneo, cioè di attivazione delle sinapsi, che è decisamente non nulla. È come avere un tubo che ogni tanto perde da solo quando vuole lui. Quindi, per molti motivi, il nostro cervello è non deterministico. E la cosa incredibile è che la chiave, la chiave di volta, dice il GPD, è stato proprio quando si è introdotto questo fattore di probabilismo, e quindi non determinismo, nel modello, che è abbastanza, insomma, filosoficamente interessante. In termini tecnici si parla di temperatura. Vedete gli esempi? A bassa temperatura, più noiosi, più prevedibili, e invece quindi ad alta temperatura, più umani, più interessanti. Ecco, a questo punto, di nuovo, a cosa serve in medicina tutto questo? Beh, qui abbiamo un programma che è in grado di, sostanzialmente di, quasi, non dico di capire, ma di analizzare i testi, in maniera proprio semantica, e anche automatica. Ecco, in medicina cosa ci può servire? A tante cose. Beh, innanzitutto, ci può servire per navigare nella marea sterminata di letteratura, perché è decisamente oltre le capacità dell'essere umano, dal punto di vista della dimensione. In secondo luogo, ci può servire, per esempio, per creare dataset clinici, su cui puoi fare statistiche. Per esempio, crearli in maniera più rigorosa, più, anche standardizzata, quindi di maggiore qualità, e con costi decisamente inferiori. E poi un'altra cosa può essere quella di affiancare, guardate bene, non sostituire, ma affiancare il medico, per dargli una mano, così che il medico possa risparmiare tempo sui casi più obbi, e possa concentrare tutta la propria attenzione sui casi più difficili, dove è veramente richiesta la sua competenza. E a questo punto vi faccio una domanda. Secondo voi, quando è che si prevede, secondo le previsioni attuali, che un paziente vero possa interfacciarsi direttamente con un robot, anziché con il medico. Sto parlando qui di pazienti veri, non di trial. Ecco, quindi chi dice che è già stato fatto sei anni fa, oggi, si può fare fra un anno, fra sei anni, o fra dodici anni? Beh, la risposta vi sorprenderà. 2017, Londra, i pazienti, i cittadini, potevano scegliere se quando chiamavano il GP, cioè il medico di base, se interfacciarsi con il medico, oppure con un bot che faceva il triage per loro. Questo, 2017, che in termini di intelligenza artificiale vuol dire paleolitica, l'età della pietra proprio. Adesso che c'è già il GPT, lascio a voi immaginare cosa sta per succedere nei prossimi anni, se non nei prossimi mesi. Bene, quindi ora sapete cos'è l'AI tradizionale? Discriminativa, cioè, classificazione e regressione. Sapete cos'è l'AI di cui si parla tanto sui giornali in questi giorni? Che è quella generativa, come per esempio il Natural Language Processing, cioè appunto c'è GPT e affini. vediamo un attimo le conseguenze sociali. Ecco, ora, il punto è questo, a me fa sorridere quanto, quando nei giornali, nel discorso pubblico, alle volte viene quasi implicitamente trattata l'AI come se ora noi fossimo chiamati a scegliere se introdurla o meno nelle nostre vite, quando non è più una scelta. queste, in larga parte, stupidaggini sono, fanno rima con tante stupidaggini che sono state dette quando sono stati introdotti. L'aeroplano, la lampadina, il telefono, internet. Siamo d'accordo che quando è stato introdotto il telefono ostinarsi a usare il telegrafo fosse una stupidaggine? Ecco, siamo in un contesto simile. È un cambiamento epocale e non sarà per niente facile affrontarlo, però siamo di fronte a un cambiamento epocale, questo è il punto. Vi faccio un esempio. queste tecniche sono in grado di moltiplicare la produttività di un individuo, di un lavoratore, di diversi fattori. Per esempio, io sostanzialmente faccio, io programmo da quando avevo 10 anni e attualmente sostanzialmente faccio programmatore nelle mie ricerche. Io non conosco un singolo collega oltre al sottoscritto che non passi la sua intera giornata lavorativa con qualche tipo di copilot, cioè cose simili a CagPT, aperto. Per un motivo molto semplice, in un giorno programmi il triplo, viene fuori triplo del codice. Ma vi pare che uno possa rimanere competitivo se si ostina a non usare queste tecniche quando tutti i suoi colleghi nella stessa giornata lavorativa fanno il triplo? Non è pensabile, ovviamente. E questo, chiaramente, è un problema sociale perché sta succedendo quello che è capitato con la rivoluzione industriale nell'arco di due anni anziché di un secolo. Quindi avrà un impatto sociale enorme. Molte persone fra pochi anni si ritroveranno a fare un lavoro che è completamente diverso da quello che facevano prima. E certo che non sarà facile adattarsi. Sarebbe molto bello se potessimo tornare indietro, sì, effettivamente le cose erano più semplici prima. Possiamo farlo? No. Anche perché appunto la frittata è fatta ormai, cioè la scoperta è là fuori. Il fatto che, per esempio, sappiamo che se prendiamo questi transformer, li alleniamo su questi grandissimi computer, riusciamo a fare dei task che fino a ieri hanno fatti solo dall'uomo? Ormai si sa. Quindi non si può tornare indietro. Se anche noi ci ostinassimo a tornare indietro, qualcun altro lo farà per noi. L'altra però, se non altro, l'altro lato della medaglia è questo, che quantomeno l'accesso a determinate professioni diventerà più facile. Pensate alla programmazione. Prima, per imparare programmare, dovevi impararti ogni singolo linguaggio con una larghissima componente mnemonica. Oggi, scrivi un testo, chiedi a Charlie Pt o chi per lui di tradurlo in C Sharp o in Java o in Python. Infatti si dice il linguaggio di programmazione del futuro è l'inglese. Perché basta scrivere in linguaggio naturale e ci pensa il bot a tradurre. Quindi, per esempio, diventare ingegnere magari in futuro sarà più semplice, più breve, perché il lato mnemonico dell'apprendimento sarà ridotto, sarà meno quantitativamente cospicuo. Quindi, molti mestieri cambieranno, però, alla fine, quello che cambierà è soprattutto a chi è dedicato l'atto di generare i contenuti. Però, l'essere umano diventerà quello che li valuta alla fine. Prendiamo un artista. Certo, fino a ieri disegnava tutti i suoi disegni a mano, oggi li può generare, però, l'artista rimane la persona con la sensibilità artistica in grado di scegliere qual è il disegno appropriato per una determinata applicazione. Quindi, l'atto che verrà lasciato all'uomo sarà quello di decisore, mentre l'atto più noioso di scrivere i riassunti, generare i disegni, eccetera, si può automatizzare. E, del resto, voi mi fidereste a lasciare la vostra carta di credito in mano ad un bot, per quanto bravo? Io no, personalmente. Quindi, la decisione vorrei farla io come essere umano, la stessa cosa vale per la clinica, il medico, il medico è quello che alla fine decide che quella soluzione lì proposta dalla macchina era appropriata, con molti problemi che andranno risolti, ovviamente. Ecco, quindi, in conclusione, una cosa è sicura, c'è una categoria di persone che effettivamente è a rischio di perdere il lavoro, sono quelli che si ostineranno a non voler adeguarsi alla nostra epoca. E, quindi, per questo sarà anche fondamentale una cosa, che il regolatore, cioè i governi, facciano sì che l'accesso a queste tecniche sia universale, perché, vedete, se dovesse succedere, se dovesse verificarsi la circostanza in fausta che soltanto un sottogruppo della popolazione avrà accesso a questi superpoteri, è la fine della mobilità sociale, perché ci ritroveremo davvero ad avere cittadini di serie A e cittadini di serie B. Quindi, sarà fondamentale che i regolatori garantiscano l'accesso a queste tecniche. E, in conclusione, io spero di avervi lasciato tre cose. Primo, cos'è l'AI tradizionale, classificazione e regressione. secondo, cos'è l'AI generativa, quindi sostanzialmente processare testi, generare testi o generare immagini, eccetera, e come funziona dal punto di vista della fantasia della macchina. E terzo, il fatto che oggi l'AI non è più una nostra scele, ormai la frittata è fatta. L'AI non vi ruberà il lavoro, sarà qualcuno in carne ed ossa che usa l'AI a robarvi il lavoro. Grazie. Grazie. Grazie. Grazie. Grazie. Grazie.